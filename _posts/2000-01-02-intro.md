---
title: "Introduction"
bg: blue
color: white
fa-icon: quote-left
---

*This work explores how temporal regularization in egocentric videos may have a positive or negative impact in saliency prediction depending on the viewer behavior. Our study is based on the new EgoMon dataset, which consists of seven videos recorded by three subjects in both free-viewing and task-driven set ups. We predict a frame-based saliency prediction over the frames of each video clip, as well as a temporally regularized version based on deep neural networks. Our results indicate that the NSS saliency metric improves during task-driven activities, but that it clearly drops during free-viewing. Encouraged by the good results in task-driven activities, we also computed and publish the saliency maps for the EPIC Kitchens dataset.*


If you find this work useful, please consider citing:

<i>
Panagiotis Linardos, Eva Mohedano, Monica Cherto, Cathal Gurrin, Xavier Giro-i-Nieto. "Temporal Saliency Adaptation in Egocentric Videos", Extended abstract at the ECCV Workshop on Egocentric Perception, Interaction and Computing (EPIC), 2018.
</i>

<pre>
@inproceedings{Linardos2018videosalgan,
title={Temporal Saliency Adaptation in Egocentric Videos},
author={Panagiotis Linardos, Eva Mohedano, Monica Cherto, Cathal Gurrin, Xavier Giro-i-Nieto},
journal={arXiv preprint arXiv:1808.09559},
year={2018}
}
</pre>


Find our paper on [arXiv](https://arxiv.org/abs/1808.09559) or download the PDF directly from [here](./linardos-2018-eccvw.pdf).
